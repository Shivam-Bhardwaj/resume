---
id: senior-robotics-software-engineer-autonomy
role: Senior Robotics Software Engineer – Autonomy & Perception
company: Example Autonomous Robotics Co.
---

# Senior Robotics Software Engineer – Autonomy & Perception

## About the Role
You will design and implement real-time autonomy and perception software for a fleet of mobile robots operating in dynamic indoor and outdoor environments. You will work across SLAM, sensor fusion, and motion planning, from research prototypes to production deployments on embedded edge platforms.

## Responsibilities
- Design, implement, and optimize real-time **SLAM** pipelines (Lidar, visual, and multi-sensor) using **C++14/17** and **Python** on Linux.
- Develop and maintain **ROS/ROS2** nodes for localization, mapping, and navigation (**Nav2**, **MoveIt**).
- Build **sensor fusion** modules combining **IMU, wheel odometry, GNSS/RTK, and Lidar/Depth cameras** using **Kalman Filters** and related estimation techniques.
- Implement perception algorithms using **OpenCV**, **YOLO**, and related deep-learning models for obstacle detection and scene understanding.
- Deploy algorithms to embedded compute platforms (e.g., **NVIDIA Jetson**, x86 edge PCs), including profiling and optimization for real-time performance.
- Collaborate with hardware, firmware, and systems engineers to bring up new sensor configurations and tune the full stack in the field.
- Contribute to data collection, labeling, and evaluation pipelines to continuously improve autonomy performance.
- Write high-quality, well-tested code and participate in design and code reviews.

## Requirements
- B.S. or higher in Robotics, Computer Science, Electrical/Mechanical Engineering, or a related field.
- 4+ years of experience developing production-quality robotics or perception software.
- Strong proficiency in **C++ (14/17)** and **Python**, including modern tooling and debugging on Linux.
- Hands-on experience with **ROS** or **ROS2** on real robots, including navigation and motion-planning stacks.
- Practical experience with **SLAM** (e.g., GMapping, Cartographer, ORB-SLAM, LOAM) and state estimation.
- Experience integrating and tuning sensors such as **Velodyne/Ouster Lidars**, **stereo or depth cameras**, and **IMUs**.
- Familiarity with **sensor fusion** techniques (EKF/UKF, factor graphs) and optimization libraries (e.g., **g2o**, **Ceres**).
- Experience deploying and debugging software on embedded platforms (Jetson, industrial PCs, or similar).
- Strong software engineering fundamentals: version control (Git), CI/CD, testing, and code review practices.

## Nice to Have
- Experience with multi-robot systems or large-scale fleet deployments.
- Background in **LLM agents** or higher-level autonomy behaviors.
- Exposure to **cloud robotics** stacks (data pipelines, remote monitoring, over-the-air updates).